---
# Neural collapse config file. All must be specified
Model:
  model-name: mlp_large      # Name of model in "our_models"
  embedding-layers: [
    fc,
    #relu
  ]     # Intermediate layers to use for NC loss with weightings (True=>All layers/default)

Data:
  dataset-id: imagenet      # Which dataset-getter to use. Note that shapes are provided by the dataset
  batch-size: 128        # Mini-batch size
  do-augmentation: False # Whether to do data augmentation

Optimizer:
  loss: mseloss
  weight-decay: 2.e-4    # Weight decay
  lr: 0.067              # Learning rate
  lr-decay: 0.2
  lr-decay-steps: 3      # Number of learning rate decay steps
  momentum: 0.9          # Optimizer momentum
  epochs: 350            # Number of epochs to train for
  warmup_epochs: 0       # Number of epochs to do linear lr-warmup for

Logging:
  # When to store weights and calculate measurements
  save-dir: logs/mlp_large/mnist
  # log-interval: 10        # At what interval to log checkpoints. Always includes first 10 epochs
  log-epochs: [0, 1, 2, 3, 4, 5, 7, 10, 14, 20, 30, 40, 50, 60, 80, 100, 125, 150, 175, 200, 225, 250, 275, 300]  # Overrides log-interval

Measurements:
  measures: True
...
