---
# Neural collapse config file. All must be specified
Model:
  model-name: None            # Name of model in "our_models"
  embedding-layers: None # Intermediate layers to use for NC loss with weightings. "^" used to indicate start of network.

Data:
  dataset-id: None       # Which dataset-getter to use. Note that shapes are provided by the dataset
  batch-size: 32        # Mini-batch size
  do-augmentation: False # Whether to do data augmentation

Optimizer:
  loss: mseloss
  weight-decay: 5.e-4    # Weight decay
  lr: 0.067              # Learning rate
  lr-decay: 0.1
  lr-decay-steps: 3      # Number of learning rate decay steps
  momentum: 0.9          # Optimizer momentum
  epochs: 2              # Number of epochs to train for
  warmup_epochs: 0       # Number of epochs to do linear lr-warmup for

Logging:
  # When to store weights and calculate measurements
  save-dir: logs/matrix/debug
  # log-interval: 10        # At what interval to log checkpoints. Always includes first 10 epochs
  log-epochs: [0, 1, 2, 3, 5, 10, 20, 30, 40, 50, 60, 80, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350]  # Overrides log-interval

Measurements:
  measures: None

# Matrix for parsing into multiple configs to run with slurm
# Parsed as follows:
## All innermost values (leaves)  must be given in a list.
## For the current dictionairy level:
##   Any key other than "_Exclusive" is parsed and the innermost list of that key is used in the matrix.
##   If the key is _Exclusive, assume mutual exclusivity within the list of its contents,
##   and choose one of them to parse as another equivalent dictionary of values.
Matrix:
  _Exclusive:
    # resnet18:
    #   Model:
    #     model-name: [resnet18]
    #     embedding-layers: [[
    #       # ^conv1, ^bn1, ^relu, ^maxpool,
    #       ^layer1.0, ^layer1.1,
    #       ^layer2.0, ^layer2.1,
    #       ^layer3.0, ^layer3.1,
    #       ^layer4.0, ^layer4.1,
    #       ^avgpool, ^fc
    #     ]]
    mlp:
      Model:
        model-name: [mlp_small, mlp_single]
        # model-name: [mlp, mlp_nobn, mlp_large, mlp_large_nobn, mlp_wide, mlp_wide_nobn, mlp_xwide, mlp_xwide_nobn]
        embedding-layers: [[fc]]
    linear:
      Model:
        model-name: [mlp_linear]
        embedding-layers: [True]
    # vgg16:
    #   Model:
    #     model-name: [vgg16]
    #     embedding_layers: [[
    #       features.0, features.2, features.4,
    #       features.5, features.7, features.9,
    #       features.10, features.12, features.14, features.16,
    #       features.17, features.19, features.21, features.23,
    #       features.24, features.26, features.28, features.30,
    #       avgpool,
    #       classifier.0, classifier.3, classifier.6,
    #     ]]
    # vgg16_bn:
    #   Model:
    #     model-name: [vgg16_bn]
    #     embedding_layers: [[
    #       features.0, features.3, features.6,
    #       features.7, features.10, features.13,
    #       features.14, features.17, features.20, features.23,
    #       features.24, features.27, features.30, features.33,
    #       features.34, features.37, features.40, features.43,
    #       avgpool,
    #       classifier.0, classifier.3, classifier.6,
    #     ]]
  Data:
    dataset-id: [MNIST_debug]
    # dataset-id: [MNIST, FashionMNIST, cifar10, svhn, stl10, cifar100]
  Measurements:
    measures: [[Accuracy]]
  Optimizer:
    lr: [0.01, 0.02]
...
